apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: naglfar-imdb-benching-
spec:
  entrypoint: starter
  onExit: delete-ns
  arguments:
    parameters:
      - name: queries
        value: "q1,q2,q3,q4,q6,q7,q8,q9,q10,q11,q12,q13,q14,q15,q16,q17,q18,q19,q20,q21,q22"
      ######################################### current part
      - name: release                           # release version: nightly
        value: nightly
      - name: tidb-url
        value: "http://fileserver.pingcap.net/download/builds/pingcap/tidb/2ce238f5857e37b7f07a98088576621b0399f91f/centos7/tidb-server.tar.gz"
      - name: tikv-url
        value: "http://fileserver.pingcap.net/download/builds/pingcap/tikv/d71c78ef7c74b65e429ce24bd91389d06eb8ec0b/centos7/tikv-server.tar.gz"
      - name: pd-url
        value: "http://fileserver.pingcap.net/download/builds/pingcap/pd/fa65de5a11fe0b2e6a1783f5af4c7b6e81ddd271/centos7/pd-server.tar.gz"
      - name: toolset-tag                       # we use br to restore data, so you need fill in the toolset version
        value: tidb-5.0-rc                      # option: latest | tidb-5.0-rc . latest for master
      ######################################### baseline part
      - name: baseline-release
        value: nightly
      - name: baseline-tidb-url                 # if need to patch baseline tidb binary version
        value: ""
      - name: baseline-tikv-url
        value: ""
      - name: baseline-pd-url
        value: ""
      - name: baseline-toolset-tag              # we use br to restore data, so you need fill in the toolset version
        value: latest                           # option: latest | tidb-5.0-rc. latest for master
  templates:
    - name: starter
      steps:
        - - name: create-ns
            template: create-ns
        - - name: request-cluster
            template: request-cluster
        - - name: create-cluster
            template: create-cluster
            arguments:
              parameters: [ { name: release-branch, value: "{{workflow.parameters.release}}" },
                            { name: tidb-url, value: "{{workflow.parameters.tidb-url}}" },
                            { name: tikv-url, value: "{{workflow.parameters.tikv-url}}" },
                            { name: pd-url, value: "{{workflow.parameters.pd-url}}" } ]
        - - name: importer-logs-1
            template: importer-logs
            arguments:
              parameters: [ { name: toolset-tag,   value: "{{workflow.parameters.toolset-tag}}" },
                            { name: release-branch, value: "{{workflow.parameters.release}}" } ]
        - - name: benching-logs-1
            template: benching-logs
        - - name: uninstall-cluster
            template: uninstall-cluster
        - - name: create-cluster-baseline
            template: create-cluster
            arguments:
              parameters: [ { name: release-branch, value: "{{workflow.parameters.baseline-release}}" },
                            { name: tidb-url, value: "{{workflow.parameters.baseline-tidb-url}}" },
                            { name: tikv-url, value: "{{workflow.parameters.baseline-tikv-url}}" },
                            { name: pd-url, value: "{{workflow.parameters.baseline-pd-url}}" } ]
        - - name: importer-logs-2
            template: importer-logs
            arguments:
              parameters: [ { name: toolset-tag,   value: "{{workflow.parameters.baseline-toolset-tag}}" },
                            { name: release-branch, value: "{{workflow.parameters.baseline-release}}" } ]
        - - name: benching-logs-2
            template: benching-logs
    - name: importer-logs
      inputs:
        parameters:
          - name: toolset-tag
          - name: release-branch
      steps:
        - - name: importing
            template: importing
            arguments:
              parameters: [ { name: toolset-tag,    value: "{{inputs.parameters.toolset-tag}}" },
                            { name: release-branch, value: "{{inputs.parameters.release-branch}}" }]
          - name: importing-logs
            template: logs
            arguments:
              parameters: [ { name: workload_name, value: "imdb-importing" } ]
        - - name: importing-deletion
            template: workload-deletion
            arguments:
              parameters: [ { name: workload_name, value: "imdb-importing" } ]
    - name: benching-logs
      steps:
        - - name: benching
            template: benching
          - name: benching-logs
            template: logs
            arguments:
              parameters: [ { name: workload_name, value: "imdb-benching" } ]
        - - name: importing-deletion
            template: workload-deletion
            arguments:
              parameters: [ { name: workload_name, value: "imdb-benching" } ]
    - name: logs
      inputs:
        parameters:
          - name: workload_name
      container:
        name: logs
        image: 'argoproj/argoexec:latest'
        imagePullPolicy: IfNotPresent
        command:
          - sh
          - '-c'
          - |
            while true
            do
                state=`kubectl get tw {{inputs.parameters.workload_name}} -n {{workflow.name}} -ojsonpath='{.status.state}' || echo pending`
                if [ "running" = "$state" ]; then
                    break
                fi
                if [ "succeeded" = "$state" ]; then
                    break
                fi
                if [ "failed" = "$state" ]; then
                    break
                fi
                echo "workload isn't already now. Wait 10s..."
                sleep 10
            done
            curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/PingCAP-QE/Naglfar/master/scripts/kubectl-naglfar-installer.sh | sh
            export PATH=$PATH:/root/.Naglfar/bin
            naglfar logs {{inputs.parameters.workload_name}} -n {{workflow.name}} --follow
    - name: request-cluster
      resource:
        action: create
        successCondition: status.state = ready
        manifest: |
          apiVersion: naglfar.pingcap.com/v1
          kind: TestResourceRequest
          metadata:
            name: tidb-cluster
            namespace: {{workflow.name}}
          spec:
            machines:
              - name: m1
                exclusive: true
              - name: m2
                exclusive: true
            items:
              - name: tidb
                spec:
                  memory: 64GB
                  cores: 32
                  machine: m1
              - name: pd
                spec:
                  memory: 8GB
                  cores: 2
                  machine: m1
              - name: tikv-1
                spec:
                  memory: 64GB
                  cores: 32
                  disks:
                    disk1:
                      kind: nvme
                      mountPath: /disk1
                  machine: m2
              - name: workload
                spec:
                  memory: 8GB
                  cores: 4
                  machine: m2
    - name: create-cluster
      inputs:
        parameters:
          - name: release-branch
          - name: tidb-url
          - name: tikv-url
          - name: pd-url
      resource:
        action: create
        successCondition: status.state = ready
        manifest: |
          apiVersion: naglfar.pingcap.com/v1
          kind: TestClusterTopology
          metadata:
            name: tidb-cluster
            namespace: {{workflow.name}}
          spec:
            resourceRequest: tidb-cluster
            tidbCluster:
              serverConfigs:
                tidb: |-
                tikv: |-
                  #rocksdb.defaultcf.block-cache-size: "16GB"
                  #rocksdb.writecf.block-cache-size: "9GB"
                  #rocksdb.lockcf.block-cache-size: "1GB"
                pd: |-
              version:
                version: {{inputs.parameters.release-branch}}
                tidbDownloadURL: {{inputs.parameters.tidb-url}}
                tikvDownloadURL: {{inputs.parameters.tikv-url}}
                pdDownloadURL: {{inputs.parameters.pd-url}}
              control: tidb
              tikv:
                - host: tikv-1
                  port: 20160
                  statusPort: 20180
                  deployDir: /disk1/deploy/tikv-20160
                  dataDir: /disk1/data/tikv-20160
                  logDir: /disk1/deploy/tikv-20160/log
              tidb:
                - host: tidb
                  deployDir: /disk1/deploy/tidb-4000
              pd:
                - host: pd
                  deployDir: /disk1/deploy/pd-2379
                  dataDir: /disk1/data/pd-2379
                  logDir: /disk1/deploy/pd-2379/log
              monitor:
                - host: tidb
                  deployDir: /disk1/deploy/prometheus-8249
                  dataDir: /disk1/deploy/prometheus-8249/data
              grafana:
                - host: tidb
                  deployDir: /disk1/deploy/grafana-3000
    - name: uninstall-cluster
      resource:
        action: delete
        manifest: |
          apiVersion: naglfar.pingcap.com/v1
          kind: TestClusterTopology
          metadata:
            name: tidb-cluster
            namespace: {{workflow.name}}
    - name: importing
      inputs:
        parameters:
          - name: toolset-tag
          - name: release-branch
      resource:
        action: create
        successCondition: status.state = succeeded
        failureCondition: status.state = failed
        manifest: |
          apiVersion: naglfar.pingcap.com/v1
          kind: TestWorkload
          metadata:
            name: imdb-importing
            namespace: {{workflow.name}}
          spec:
            clusterTopologies:
              - name: tidb-cluster
                aliasName: cluster
            workloads:
              - name: imdb-importing
                dockerContainer:
                  resourceRequest:
                    name: tidb-cluster
                    node: workload
                  image: "hub.pingcap.net/mahjonp/bench-toolset:{{inputs.parameters.toolset-tag}}"
                  imagePullPolicy: IfNotPresent
                  command:
                    - /bin/bash
                    - -c
                    - |
                      #!/bin/bash
                      set -ex
                      export AWS_ACCESS_KEY_ID=minioadmin AWS_SECRET_ACCESS_KEY=minioadmin
                      tidb=`echo $cluster_tidb0 | awk -F ":" '{print $1}'`
                      pd=`echo $cluster_pd0 | awk -F ":" '{print $1}'`
                      release_branch="{{inputs.parameters.release-branch}}"

                      if [[ ${release_branch:0:4} == "v5.0" ]]; then
                        br restore db --db=imdb --pd $pd:2379 --storage s3://benchmark/imdb \
                          --s3.endpoint http://172.16.5.109:9000 --send-credentials-to-tikv=true
                      elif [[ ${release_branch} == "nightly" ]]; then
                        br restore db --db=imdb --pd $pd:2379 --storage s3://benchmark/imdb \
                          --s3.endpoint http://172.16.5.109:9000 --send-credentials-to-tikv=true
                      else
                        echo "illegal release_branch: $release_branch"
                        exit 1
                      fi
    - name: benching
      resource:
        action: create
        successCondition: status.state = succeeded
        failureCondition: status.state = failed
        manifest: |
          apiVersion: naglfar.pingcap.com/v1
          kind: TestWorkload
          metadata:
            name: imdb-benching
            namespace: {{workflow.name}}
          spec:
            clusterTopologies:
              - name: tidb-cluster
                aliasName: cluster
            workloads:
              - name: imdb-benching
                dockerContainer:
                  resourceRequest:
                    name: tidb-cluster
                    node: workload
                  image: "hub.pingcap.net/mahjonp/bench-toolset"
                  imagePullPolicy: IfNotPresent
                  command:
                    - /bin/bash
                    - -c
                    - |
                      set -ex
                      curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/chaos-mesh/horoscope/master/install.sh | sh
                      git clone https://github.com/chaos-mesh/horoscope.git
                      cd horoscope/benchmark/job
                      mv queries queries.back && mkdir queries

                      sqls=(
                               20a.sql 20b.sql 20c.sql 21a.sql 21b.sql 21c.sql 23a.sql 23b.sql 23c.sql 24a.sql 24b.sql 27a.sql 27b.sql 27c.sql 29a.sql 29b.sql 29c.sql
                               2a.sql 2b.sql 2c.sql 2d.sql
                               32a.sql 32b.sql 3a.sql 3b.sql 3c.sql
                               10a.sql 11a.sql 11b.sql 11c.sql 15a.sql 15b.sql 15c.sql 15d.sql 16a.sql 16b.sql 16c.sql 16d.sql 17a.sql 17b.sql 17c.sql 17d.sql 17e.sql 17f.sql 19a.sql 19b.sql 19c.sql 19d.sql
                               5a.sql 5b.sql 5c.sql 6a.sql 6b.sql 6c.sql 6d.sql 6e.sql 6f.sql 7a.sql 7b.sql 7c.sql 8a.sql 8b.sql 8c.sql 8d.sql 9a.sql 9b.sql 9c.sql 9d.sql
                           )
                      for file in "${sqls[@]}"; do
                        cp queries.back/$file queries/$file
                      done
                      tidb=`echo $cluster_tidb0 | awk -F ":" '{print $1}'`
                      /root/.horo/bin/horo -d "root@tcp($tidb:4000)/imdb?multiStatements=true" -w . init
                      /root/.horo/bin/horo bench --round 4
    - name: workload-deletion
      inputs:
        parameters:
          - name: workload_name
      resource:
        action: delete
        manifest: |
          apiVersion: naglfar.pingcap.com/v1
          kind: TestWorkload
          metadata:
            name: {{inputs.parameters.workload_name}}
            namespace: {{workflow.name}}
    - name: create-ns
      resource:
        action: create
        successCondition: status.phase = Active
        manifest: |
          apiVersion: v1
          kind: Namespace
          metadata:
            name: {{workflow.name}}
    - name: delete-ns
      resource:
        action: delete
        manifest: |
          apiVersion: v1
          kind: Namespace
          metadata:
            name: {{workflow.name}}
